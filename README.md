ğŸš€ End-to-End Sales Data Engineering Pipeline PySpark â€¢ PostgreSQL â€¢ KPI
Data Mart â€¢ Analytical SQL

============================================================

ğŸ“Œ Project Overview

This project implements a complete end-to-end data engineering pipeline
processing 100,000+ sales records using PySpark for distributed data
processing and PostgreSQL for structured analytical reporting.

Workflow: - Raw data ingestion - Data cleaning & transformation -
Feature engineering - KPI aggregation - Data mart design - Business
analytics layer

============================================================

ğŸ— System Architecture

Raw CSV Dataset (100k rows) â”‚ â–¼ PySpark ETL Layer - Data cleaning - Date
standardization - Feature engineering - KPI computation â”‚ â–¼ KPI Data
Export â”‚ â–¼ PostgreSQL Data Mart (kpi schema) â”‚ â–¼ Analytical SQL Queries

============================================================

âš™ ETL Layer (PySpark)

The ETL pipeline performs: - Schema inference and column normalization -
Date parsing & validation - Profit margin calculation - Time-based
feature generation (year, month) - KPI aggregations using Spark
transformations

Generated KPIs: - Total revenue & total profit - Monthly revenue and
profit trends - Channel performance analysis - Top-performing
countries - Item type profitability - Revenue distribution by order
priority

============================================================

ğŸ—„ Data Mart Design (PostgreSQL)

Schema: kpi

Tables: - summary - monthly_kpi - top_countries - channel_kpi -
item_kpi - priority_kpi

============================================================

ğŸ” Analytical SQL Example

SELECT sales_channel, revenue, ROUND( ((revenue / SUM(revenue) OVER
()) * 100)::numeric, 2 ) AS revenue_share_pct FROM kpi.channel_kpi;

============================================================

ğŸ›  Technologies Used

-   PySpark
-   PostgreSQL
-   SQL (CTEs, Window Functions, Aggregations)
-   Pandas
-   pgAdmin
-   Git

============================================================

ğŸ’¼ Skills Demonstrated

âœ” Data Engineering Workflow
âœ” Distributed Data Processing
âœ” KPI Data Mart Design
âœ” Advanced SQL Analytics
âœ” Business-Oriented Data Interpretation

============================================================

Author: Omar ahmed Data Engineer | SQL & Spark Specialist
